{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offsite - Featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'Home_credit_data/'\n",
    "app_train = pd.read_csv(DATA_PATH + 'application_train.csv')\n",
    "# app_test = pd.read_csv(DATA_PATH + 'application_test.csv')\n",
    "bureau = pd.read_csv(DATA_PATH + 'bureau.csv')\n",
    "bureau_balance = pd.read_csv(DATA_PATH + 'bureau_balance.csv')\n",
    "cash = pd.read_csv(DATA_PATH + 'POS_CASH_balance.csv')\n",
    "credit = pd.read_csv(DATA_PATH + 'credit_card_balance.csv')\n",
    "previous = pd.read_csv(DATA_PATH + 'previous_application.csv')\n",
    "installments = pd.read_csv(DATA_PATH + 'installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick cleaning: unrealistic days value (365243 days is > 1000 years)\n",
    "app_train = app_train.replace({365243: np.nan})\n",
    "# app_test = app_test.replace({365243: np.nan})\n",
    "bureau = bureau.replace({365243: np.nan})\n",
    "bureau_balance = bureau_balance.replace({365243: np.nan})\n",
    "cash = cash.replace({365243: np.nan})\n",
    "credit = credit.replace({365243: np.nan})\n",
    "previous = previous.replace({365243: np.nan})\n",
    "installments = installments.replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR ---\n",
      "SK_ID_CURR <class 'numpy.float64'>\n",
      "SK_ID_CURR <class 'numpy.float64'>\n",
      "SK_ID_CURR <class 'numpy.float64'>\n",
      "SK_ID_CURR <class 'numpy.int64'>\n",
      "SK_ID_CURR <class 'numpy.float64'>\n",
      "SK_ID_CURR <class 'numpy.float64'>\n",
      "SK_ID_BUREAU ---\n",
      "SK_ID_BUREAU <class 'numpy.float64'>\n",
      "SK_ID_BUREAU <class 'numpy.int64'>\n",
      "SK_ID_PREV ---\n",
      "SK_ID_PREV <class 'numpy.float64'>\n",
      "SK_ID_PREV <class 'numpy.int64'>\n",
      "SK_ID_PREV <class 'numpy.float64'>\n",
      "SK_ID_PREV <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# checking whether keys are of the same type (to be able to add relationships)\n",
    "datasets = [app_train, bureau, bureau_balance, cash, credit, previous, installments]\n",
    "keys = ['SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV']\n",
    "for key in keys:\n",
    "  print(key, '---')\n",
    "  for dataset in datasets:\n",
    "    if key in dataset:\n",
    "      print(key, type(dataset[key][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmonizing keys\n",
    "for key in keys:\n",
    "  for dataset in datasets:\n",
    "    if key in dataset:\n",
    "      dataset[key] = dataset[key].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 boolean variables in app_train.\n"
     ]
    }
   ],
   "source": [
    "# identifying boolean variables (minus the target variable)\n",
    "app_train_types = {}\n",
    "for col in app_train:\n",
    "  if (app_train[col].nunique() == 2) and (app_train[col].dtype == float):\n",
    "    app_train_types[col] = ft.variable_types.Boolean\n",
    "del app_train_types['TARGET']\n",
    "print(len(app_train_types), 'boolean variables in app_train.')\n",
    "\n",
    "# adding ordinal variables to app_train_types\n",
    "app_train_types['REGION_RATING_CLIENT'] = ft.variable_types.Ordinal\n",
    "app_train_types['REGION_RATING_CLIENT_W_CITY'] = ft.variable_types.Ordinal\n",
    "app_train_types['HOUR_APPR_PROCESS_START'] = ft.variable_types.Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 boolean variables in previous.\n"
     ]
    }
   ],
   "source": [
    "# same thing with the dataframe called previous\n",
    "previous_types = {}\n",
    "for col in previous:\n",
    "  if (previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "    previous_types[col] = ft.variable_types.Boolean\n",
    "print(len(previous_types), 'boolean variables in previous.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of the column 'SK_ID_CURR' where we don't need it\n",
    "# (and we want to avoid it being treated as a variable when it's actually an ID)\n",
    "installments = installments.drop(columns = ['SK_ID_CURR'])\n",
    "credit = credit.drop(columns = ['SK_ID_CURR'])\n",
    "cash = cash.drop(columns = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an entity set\n",
    "es = ft.EntitySet(id='clients')\n",
    "\n",
    "# step 1: adding the entities that have a unique key\n",
    "es = es.entity_from_dataframe(entity_id='app_train',\n",
    "                              dataframe=app_train,\n",
    "                              index='SK_ID_CURR',\n",
    "                              variable_types=app_train_types)\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='bureau',\n",
    "                              dataframe=bureau,\n",
    "                              index='SK_ID_BUREAU')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='previous', \n",
    "                              dataframe=previous, \n",
    "                              index='SK_ID_PREV',\n",
    "                              variable_types=previous_types)\n",
    "\n",
    "# step 2: adding entities that don't have a unique key (we have to supply a name for it)\n",
    "es = es.entity_from_dataframe(entity_id='bureau_balance',\n",
    "                             dataframe=bureau_balance,\n",
    "                             make_index=True,\n",
    "                             index='bureaubalance_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='cash',\n",
    "                             dataframe=cash,\n",
    "                             make_index=True,\n",
    "                             index='cash_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='installments',\n",
    "                             dataframe=installments,\n",
    "                             make_index=True,\n",
    "                             index='installments_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='credit',\n",
    "                             dataframe=credit,\n",
    "                             make_index=True,\n",
    "                             index='credit_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app_train [Rows: 307511, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 8]\n",
       "    installments [Rows: 13605401, Columns: 8]\n",
       "    credit [Rows: 3840312, Columns: 23]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app_train.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app_train.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationships step 1: defining relationships\n",
    "# relationship between app_train and bureau\n",
    "rel_app_bureau = ft.Relationship(es['app_train']['SK_ID_CURR'], \n",
    "                                 es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "# relationship bureau / bureau balance\n",
    "rel_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], \n",
    "                                     es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "# relationship current app / previous apps\n",
    "rel_app_previous = ft.Relationship(es['app_train']['SK_ID_CURR'], \n",
    "                                   es['previous']['SK_ID_CURR'])\n",
    "\n",
    "# relationships between previous apps and cash, installments, and credit\n",
    "rel_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], \n",
    "                                    es['cash']['SK_ID_PREV'])\n",
    "\n",
    "rel_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], \n",
    "                                            es['installments']['SK_ID_PREV'])\n",
    "\n",
    "rel_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], \n",
    "                                      es['credit']['SK_ID_PREV'])\n",
    "\n",
    "# relationships step 2: adding the relationships to the entity set\n",
    "es = es.add_relationships([rel_app_bureau, \n",
    "                           rel_bureau_balance, \n",
    "                           rel_app_previous,\n",
    "                           rel_previous_cash, \n",
    "                           rel_previous_installments, \n",
    "                           rel_previous_credit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app_train [Rows: 307511, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 8]\n",
       "    installments [Rows: 13605401, Columns: 8]\n",
       "    credit [Rows: 3840312, Columns: 23]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app_train.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app_train.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep feature synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining primitives to use for DFS\n",
    "agg_primitives =  ['sum', 'max', 'min', 'mean', 'count', 'percent_true', 'num_unique', 'mode']\n",
    "trans_primitives = ['percentile', 'and']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in the next cell, we could define seed features based on domain knowledge (eg the interest rate). Featuretools would then build additional features where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1820 features\n"
     ]
    }
   ],
   "source": [
    "# inspecting the features that will be created (only feature names and not values by passing features_only=True)\n",
    "feature_names = ft.dfs(entityset=es, \n",
    "                       target_entity='app_train',\n",
    "                       trans_primitives=trans_primitives,\n",
    "                       agg_primitives=agg_primitives, \n",
    "                       seed_features=[],\n",
    "                       max_depth=2, \n",
    "                       n_jobs=-1, \n",
    "                       verbose=1,\n",
    "                       features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: PERCENTILE(MEAN(credit.AMT_TOTAL_RECEIVABLE))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.CNT_DRAWINGS_ATM_CURRENT))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.CNT_DRAWINGS_CURRENT))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.CNT_DRAWINGS_OTHER_CURRENT))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.CNT_DRAWINGS_POS_CURRENT))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.CNT_INSTALMENT_MATURE_CUM))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.SK_DPD))>,\n",
       " <Feature: PERCENTILE(MEAN(credit.SK_DPD_DEF))>,\n",
       " <Feature: PERCENTILE(COUNT(credit))>,\n",
       " <Feature: PERCENTILE(NUM_UNIQUE(credit.NAME_CONTRACT_STATUS))>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the features to use them in the DASK notebook\n",
    "ft.save_features(feature_names, 'features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running DFS\n",
    "feature_matrix, feature_names = ft.dfs(entityset=es, \n",
    "                                       target_entity='app_train',\n",
    "                                       trans_primitives=trans_primitives,\n",
    "                                       agg_primitives=agg_primitives, \n",
    "                                       seed_features=[],\n",
    "                                       max_depth=2, \n",
    "                                       n_jobs=-1, \n",
    "                                       verbose=1,\n",
    "                                       features_only=False)\n",
    "\n",
    "feature_matrix.reset_index(inplace=True)\n",
    "feature_matrix.to_csv('feature_matrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
