{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuretools with DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'Home_credit_data/'\n",
    "app_train = pd.read_csv(DATA_PATH + 'application_train.csv')\n",
    "# app_test = pd.read_csv(DATA_PATH + 'application_test.csv')\n",
    "bureau = pd.read_csv(DATA_PATH + 'bureau.csv')\n",
    "bureau_balance = pd.read_csv(DATA_PATH + 'bureau_balance.csv')\n",
    "cash = pd.read_csv(DATA_PATH + 'POS_CASH_balance.csv')\n",
    "credit = pd.read_csv(DATA_PATH + 'credit_card_balance.csv')\n",
    "previous = pd.read_csv(DATA_PATH + 'previous_application.csv')\n",
    "installments = pd.read_csv(DATA_PATH + 'installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick cleaning: unrealistic days value (365243 days is > 1000 years)\n",
    "app_train = app_train.replace({365243: np.nan})\n",
    "# app_test = app_test.replace({365243: np.nan})\n",
    "bureau = bureau.replace({365243: np.nan})\n",
    "bureau_balance = bureau_balance.replace({365243: np.nan})\n",
    "cash = cash.replace({365243: np.nan})\n",
    "credit = credit.replace({365243: np.nan})\n",
    "previous = previous.replace({365243: np.nan})\n",
    "installments = installments.replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing types to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_variable_types(df):\n",
    "    \"\"\"Changes data types to be memory efficient\"\"\"\n",
    "    for col in df:\n",
    "        # IDs and bool to int\n",
    "        if ('SK_ID' in col):\n",
    "            df[col] = df[col].fillna(0).astype(np.int32)   \n",
    "        # objects to category\n",
    "        elif (df[col].dtype == 'object') and (df[col].nunique() < df.shape[0]):\n",
    "            df[col] = df[col].astype('category')    \n",
    "        # float64 to float32\n",
    "        elif df[col].dtype == float:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "        # int64 to int32\n",
    "        elif df[col].dtype == int:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        # bool to int\n",
    "        elif set(df[col].unique()) == {0, 1}:\n",
    "            df[col] = df[col].astype(bool) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = change_variable_types(app_train)\n",
    "bureau = change_variable_types(bureau)\n",
    "bureau_balance = change_variable_types(bureau_balance)\n",
    "cash = change_variable_types(cash)\n",
    "credit = change_variable_types(credit)\n",
    "previous = change_variable_types(previous)\n",
    "installments = change_variable_types(installments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding SK_ID_CURR to bureau_balance\n",
    "bureau_balance = bureau_balance.merge(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], \n",
    "                                      on='SK_ID_BUREAU',\n",
    "                                      how='left')\n",
    "\n",
    "# SK_ID_CURR has been added as a float64 so we call the change_variable_types function again\n",
    "bureau_balance = change_variable_types(bureau_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_datasets(clients_list, num_partition):\n",
    "    \"\"\"Partitions the datasets based on who is in the clients_list argument\"\"\"\n",
    "    # subsetting\n",
    "    app_train_subset = app_train[app_train.index.isin(clients_list)].copy()\n",
    "    bureau_subset = bureau[bureau.index.isin(clients_list)].copy()\n",
    "    bureau_balance_subset = bureau_balance[bureau_balance.index.isin(clients_list)].copy()\n",
    "    cash_subset = cash[cash.index.isin(clients_list)].copy()\n",
    "    credit_subset = credit[credit.index.isin(clients_list)].copy()\n",
    "    previous_subset = previous[previous.index.isin(clients_list)].copy()\n",
    "    installments_subset = installments[installments.index.isin(clients_list)].copy()\n",
    "    \n",
    "    # resetting indexes\n",
    "    app_train_subset = app_train_subset.reset_index()\n",
    "    bureau_subset = bureau_subset.reset_index()\n",
    "    bureau_balance_subset = bureau_balance_subset.reset_index(drop=True)\n",
    "    cash_subset = cash_subset.reset_index(drop=True)\n",
    "    credit_subset = credit_subset.reset_index(drop=True)\n",
    "    previous_subset = previous_subset.reset_index(drop=True)\n",
    "    installments_subset = installments_subset.reset_index(drop=True)\n",
    "    \n",
    "    # saving\n",
    "    # app_train_subset.to_csv('partitions/app_train' + str(num_partition) + '.csv', index=False)\n",
    "    # bureau_subset.to_csv('partitions/bureau' + str(num_partition) + '.csv', index=False)\n",
    "    # bureau_balance_subset.to_csv('partitions/bureau_balance' + str(num_partition) + '.csv', index=False)\n",
    "    # cash_subset.to_csv('partitions/cash' + str(num_partition) + '.csv', index=False)\n",
    "    # credit_subset.to_csv('partitions/credit' + str(num_partition) + '.csv', index=False)\n",
    "    # previous_subset.to_csv('partitions/previous' + str(num_partition) + '.csv', index=False)\n",
    "    # installments_subset.to_csv('partitions/installments' + str(num_partition) + '.csv', index=False)\n",
    "    \n",
    "    directory = 'partitions/part' + str(num_partition)\n",
    "    os.makedirs(directory)\n",
    "    app_train_subset.to_csv('partitions/part' + str(num_partition) + '/app_train.csv', index=False)\n",
    "    bureau_subset.to_csv('partitions/part' + str(num_partition) + '/bureau.csv', index=False)\n",
    "    bureau_balance_subset.to_csv('partitions/part' + str(num_partition) + '/bureau_balance.csv', index=False)\n",
    "    cash_subset.to_csv('partitions/part' + str(num_partition) + '/cash.csv', index=False)\n",
    "    credit_subset.to_csv('partitions/part' + str(num_partition) + '/credit.csv', index=False)\n",
    "    previous_subset.to_csv('partitions/part' + str(num_partition) + '/previous.csv', index=False)\n",
    "    installments_subset.to_csv('partitions/part' + str(num_partition) + '/installments.csv', index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.831073566277821 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = app_train.shape[0] // 80\n",
    "clients_ids_list = [list(app_train.iloc[i : i+batch_size].index) for i in range(0, app_train.shape[0], batch_size)]\n",
    "\n",
    "start = time.time()\n",
    "for n, clients_ids in enumerate(clients_ids_list):\n",
    "    partition_datasets(clients_ids, n)\n",
    "end = time.time()\n",
    "print((end - start) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_set_from_partition(path):\n",
    "    \"\"\"Creates an entity set for a partition\"\"\"\n",
    "    num_partition = int(path[15:])\n",
    "    \n",
    "    # grabbing the data\n",
    "    app_train = pd.read_csv(path + '/app_train.csv')\n",
    "    bureau = pd.read_csv(path + '/bureau.csv')\n",
    "    bureau_balance = pd.read_csv(path + '/bureau_balance.csv')\n",
    "    cash = pd.read_csv(path + '/cash.csv')\n",
    "    credit = pd.read_csv(path + '/credit.csv')\n",
    "    previous = pd.read_csv(path + '/previous.csv')\n",
    "    installments = pd.read_csv(path + '/installments.csv')\n",
    "    \n",
    "    # creating the entity set (see details in other notebook)\n",
    "    es = ft.EntitySet(id='clients')\n",
    "    es = es.entity_from_dataframe(entity_id='app_train', \n",
    "                                  dataframe=app_train, \n",
    "                                  index='SK_ID_CURR')\n",
    "    es = es.entity_from_dataframe(entity_id='bureau', \n",
    "                                  dataframe=bureau, \n",
    "                                  index='SK_ID_BUREAU')\n",
    "    es = es.entity_from_dataframe(entity_id='previous', \n",
    "                                  dataframe=previous, \n",
    "                                  index='SK_ID_PREV')\n",
    "    es = es.entity_from_dataframe(entity_id='bureau_balance', \n",
    "                                  dataframe=bureau_balance, \n",
    "                                  make_index=True, \n",
    "                                  index='bureaubalance_index')\n",
    "    es = es.entity_from_dataframe(entity_id='cash', \n",
    "                                  dataframe=cash, \n",
    "                                  make_index=True, \n",
    "                                  index='cash_index')\n",
    "    es = es.entity_from_dataframe(entity_id='installments', \n",
    "                                  dataframe=installments,\n",
    "                                  make_index=True, \n",
    "                                  index='installments_index')\n",
    "    es = es.entity_from_dataframe(entity_id='credit', \n",
    "                                  dataframe=credit,\n",
    "                                  make_index=True, \n",
    "                                  index='credit_index')\n",
    "    \n",
    "    # defining relationships (see details in other notebook) and adding them to the entity set\n",
    "    rel_app_bureau = ft.Relationship(es['app_train']['SK_ID_CURR'], \n",
    "                                     es['bureau']['SK_ID_CURR'])\n",
    "    rel_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], \n",
    "                                         es['bureau_balance']['SK_ID_BUREAU'])\n",
    "    rel_app_previous = ft.Relationship(es['app_train']['SK_ID_CURR'], \n",
    "                                       es['previous']['SK_ID_CURR'])\n",
    "    rel_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], \n",
    "                                        es['cash']['SK_ID_PREV'])\n",
    "    rel_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], \n",
    "                                                es['installments']['SK_ID_PREV'])\n",
    "    rel_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], \n",
    "                                          es['credit']['SK_ID_PREV'])\n",
    "    es = es.add_relationships([rel_app_bureau, \n",
    "                           rel_bureau_balance, \n",
    "                           rel_app_previous,\n",
    "                           rel_previous_cash, \n",
    "                           rel_previous_installments, \n",
    "                           rel_previous_credit])\n",
    "    \n",
    "    return {'es': es, 'number': num_partition}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820\n"
     ]
    }
   ],
   "source": [
    "# grabbing the features list created in the other notebook\n",
    "features_list = ft.load_features('features.txt')\n",
    "print(len(features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_matrix(es_dict, features_list):\n",
    "    \"\"\"Computes the feature matrix corresponding to defined features, for an entity set\"\"\"\n",
    "    es = es_dict['es']\n",
    "    num_partition = es_dict['number']\n",
    "    feature_matrix = ft.calculate_feature_matrix(features_list,\n",
    "                                                entityset=es,\n",
    "                                                n_jobs=1,\n",
    "                                                chunk_size=es['app_train'].df.shape[0])\n",
    "    feature_matrix.to_csv('matrices_from_partitions/feature_matrix_part' + str(num_partition) + '.csv', index=True)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partitions/part0',\n",
       " 'partitions/part1',\n",
       " 'partitions/part2',\n",
       " 'partitions/part3',\n",
       " 'partitions/part4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_list = ['partitions/part' + str(i) for i in range(0, 81)]\n",
    "paths_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeing some memory\n",
    "del app_train, bureau, bureau_balance, previous, credit, cash, installments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Use all 8 cores\n",
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inproc://10.36.117.196/12212/2': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ncores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<map-com..., npartitions=81>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a bag object\n",
    "b = db.from_sequence(paths_list)\n",
    "\n",
    "# mapping an entity set function and a feature matrix function\n",
    "b = b.map(create_entity_set_from_partition)\n",
    "b = b.map(compute_feature_matrix, features_list=features_list)\n",
    "    \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
